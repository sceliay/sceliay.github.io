<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>Lable Distribution for Multimodal Machine Learning | YRen's Blog</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/latest/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/latest/pure-min.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/latest/grids-responsive-min.min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/latest/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script type="text/javascript" src="//lib.baomitu.com/clipboard.js/latest/clipboard.min.js"></script><script type="text/javascript" src="//lib.baomitu.com/toastr.js/latest/toastr.min.js"></script><link rel="stylesheet" href="//lib.baomitu.com/toastr.js/latest/toastr.min.css"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Lable Distribution for Multimodal Machine Learning</h1><a id="logo" href="/.">YRen's Blog</a><p class="description">当你凝视深渊的时候，深渊也在凝视着你。</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 主页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/tags/"><i class="fa fa-tags"> 标签</i></a><a href="/about"><i class="fa fa-user"> 关于</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Lable Distribution for Multimodal Machine Learning</h1><div class="post-meta">2022-04-18<span> | </span><span class="category"><a href="/categories/Machine-Learning/">Machine Learning</a></span></div><a class="disqus-comment-count" href="/2022/04/18/mldl/#vcomment"><span class="valine-comment-count" data-xid="/2022/04/18/mldl/"></span><span> 条评论</span></a><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#导读"><span class="toc-number">1.</span> <span class="toc-text">导读</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#多模态标记分布学习"><span class="toc-number">2.</span> <span class="toc-text">多模态标记分布学习</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#时序多模态标记分布学习"><span class="toc-number">3.</span> <span class="toc-text">时序多模态标记分布学习</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#实验"><span class="toc-number">4.</span> <span class="toc-text">实验</span></a></li></ol></div></div><div class="post-content"><p><a href="https://link.springer.com/article/10.1007/s11704-021-0611-6" target="_blank" rel="noopener">全文链接</a></p>
<h2 id="导读"><a href="#导读" class="headerlink" title="导读"></a>导读</h2><p>多模态机器学习致力于通过多源数据来了解世界，如图像、语音和文本等。相比于单模态，多模态数据包含更多的信息，且模态之间具有互补性，因此多模态机器学习模型往往表现出比单模态更好的性能。然而，如何有效进行多模态融合，挖掘其中深层的特征表达，始终是多模态机器学习的重难点。区别于以往的多模态融合方法，本文考虑边信息引导多模态融合。提出多模态标记分布学习框架，利用边信息恢复出多模态标记分布，表示每个模态在描述示例时所占比例，然后采用多模态标记分布指导多模态融合，从而更准确的获取融合特征。针对不同的时序数据，本文进一步提出两个多模态标记分布学习算法，并分别应用于多模态情感识别与疾病诊断任务。实验结果正式了该算法优于现有先进算法。</p>
<h2 id="多模态标记分布学习"><a href="#多模态标记分布学习" class="headerlink" title="多模态标记分布学习"></a>多模态标记分布学习</h2><p>区别于以往的多模态机器学习算法仅考虑各个模态特征，本文认为多模态融合会受到环境影响，如图1所示，当视频处于昏暗的环境中，我们会更关注于音频与字幕，而当视频处于嘈杂且没有字幕的时候，我们会更关注于图像来分析视频的内容。因此，本文提出利用边信息恢复出多模态标记分布，用于表示各个模态在环境影响下对示例的描述程度，并用多模态标记分布指导多模态融合，从而获得更准确的融合特征。由于真实世界数据中，缺少多模态标记分布的确切标注，因此，我们提出了一个端到端的多模态标记分布学习框架，利用任务的监督信号，通过反馈学习来获得多模态标记分布。</p>
<p><img src="/img/example.png" alt="图1. 模态重要性示意图">。在不同环境下，各个模态在描述示例时的比重会发生变化。</p>
<p>定义 <script type="math/tex">\mathcal{X} = \mathbb{R}^{r_s} \times \mathbb{R}^{r_1} \times \mathbb{R}^{r_2} \times \cdots \times \mathbb{R}^{r_M}</script> 为输入空间，包括边信息（<script type="math/tex">r_s</script>维）与 <script type="math/tex">M</script> 个模态特征（用 <script type="math/tex">r_m</script> 表示第 <script type="math/tex">m</script> 个模态维度）。用 <script type="math/tex">\mathcal{Y} = \{y_j\}^q_{j=1}</script> 表示标记空间，共 <script type="math/tex">q</script> 个类。给定训练集 <script type="math/tex">\mathcal{D} = \{(\textbf{x}_i,\textbf{y}_i)|1 \le i \le N \}</script>，其中 <script type="math/tex">\textbf{x}_i = [ \textbf{s}_i, \textbf{x}_i^1, \textbf{x}_i^2, \cdots, \textbf{x}_i^M] \in \mathcal{X}</script> 为特征向量，包括边信息 <script type="math/tex">\textbf{s}_i</script> 与模态特征 <script type="math/tex">\textbf{x}_i^m</script>， <script type="math/tex">\textbf{y}_i \subseteq \mathcal{Y}</script> 为相应标记，<script type="math/tex">N</script>为训练集数量。则多模态标记分布学习的任务为学习一个预测模型：<script type="math/tex">f: \mathcal{X} \to 2^{\mathcal{Y}}</script> 。</p>
<p><img src="/img/mldl.png" alt="图2. 多模态标记分布学习框架。"></p>
<p>多模态标记分布学习框架如图2所示。定义 <script type="math/tex">d_{\textbf{s}}^{m} \in \mathbb{R}</script> 为第 <script type="math/tex">m</script> 个模态的描述度，则多模态标记分布为 <script type="math/tex">\textbf{d} = \{ d_{\textbf{s}}^1, d_{\textbf{s}}^{2}, \cdots, d_{\textbf{s}}^{M} \}</script>。我们假设 <script type="math/tex">d_{\textbf{s}}^{m} \in [0,1]</script>，那么所有模态可以完整描述该示例，即<script type="math/tex">\sum{ \textbf{d} } = 1</script>。由于描述度与概率分布具有相同的约束，因此 <script type="math/tex">d_{\textbf{s}}^{m}</script> 可以表示为条件概率，<script type="math/tex">d_{\textbf{s}}^{m} = P( \textbf{x}^m| \textbf{s})</script>。本文构建条件概率函数 <script type="math/tex">p(\textbf{x}^m|\textbf{s};\textbf{w})</script> 来求解：</p>
<script type="math/tex; mode=display">
\textbf{d} = p(\textbf{x}|\textbf{s};\textbf{w}) \\
 = softmax(\textbf{h}_{\textbf{d}} \textbf{w}_{\textbf{d}} + b_{\textbf{d}})</script><p>其中，<script type="math/tex">\textbf{w}_{\textbf{d}} \in \mathbb{R}^{r_{h,d} \times M}</script>为模型参数， <script type="math/tex">b_{\textbf{d}} \in \mathbb{R}</script>为偏置，<script type="math/tex">\textbf{h}_{\textbf{d}} \in \mathbb{R}^{r_{h,d}}</script>为隐含层输出，本文设置为两层隐含层：</p>
<script type="math/tex; mode=display">
\textbf{h}_{\textbf{d}} = \sigma( \textbf{h}_{\textbf{d},1} \textbf{w}_{\textbf{h},\textbf{d}} + b_{\textbf{h},\textbf{d}}) \\
\textbf{h}_{\textbf{d},1} = \sigma( \textbf{s}_a \textbf{w}_{\textbf{h},\textbf{d},1} + b_{\textbf{h},\textbf{d},1})</script><p>其中， <script type="math/tex">\textbf{w}_{\textbf{h},\textbf{d}} \in \mathbb{R}^{r_{h,d,1} \times r_{h,d}}$， $\textbf{w}_{\textbf{h},\textbf{d},1} \in \mathbb{R}^{r_s \times r_{h,d,1}}</script>，<script type="math/tex">\sigma</script>为激活函数，可以为任意非线性函数如tanh或relu等。为了获得更好的理解能力，本文采用了自注意力机制：</p>
<script type="math/tex; mode=display">
\textbf{s}_a = softmax(\frac{QK^T}{\sqrt{r_s}})V\\
Q = \textbf{s} \textbf{w}_Q\\
K = \textbf{s} \textbf{w}_K\\
V = \textbf{s} \textbf{w}_V</script><p>其中，<script type="math/tex">Q, K \in \mathbb{R}^{r_k}</script>，<script type="math/tex">V \in \mathbb{R}^{r_s}</script>，<script type="math/tex">\textbf{w}_Q , \textbf{w}_K, \in \mathbb{R}^{r_s \times r_k}$ and $\textbf{w}_V \in \mathbb{R}^{r_s \times r_s}</script>为参数矩阵。 </p>
<p>在对多模态进行融合前，我们采用线性变换将各模态特征映射到同一特征空间：</p>
<script type="math/tex; mode=display">
\widetilde{\textbf{x}}^m = \sigma( \textbf{x}^m \textbf{w}_{x,m}+b_{x,m})</script><p>再用多模态标记分布指导多模态融合：</p>
<script type="math/tex; mode=display">
\textbf{x}_F = Concat( \textbf{d} \otimes \widetilde{\textbf{x}} )\\
= [d_{\textbf{s}}^1 \widetilde{\textbf{x}}^1, d_{\textbf{s}}^2 \widetilde{\textbf{x}}^2, \cdots ,d_{\textbf{s}}^M \widetilde{\textbf{x}}^M ]</script><p>最后，我们通过前馈神经网络构建多模态融合特征到任务标记的映射：</p>
<script type="math/tex; mode=display">
\hat{\textbf{y}} = sigmoid( \textbf{h}_{\textbf{y}} \textbf{w}_{\textbf{y}} +b_{\textbf{y}}) \\
\textbf{h}_{\textbf{y}} = \sigma( \textbf{h}_{\textbf{y},1} \textbf{w}_{\textbf{h},{\textbf{y}}} + b_{\textbf{h},{\textbf{y}}}) \\
\textbf{h}_{\textbf{y},1} = \sigma(\textbf{x}_F  \textbf{w}_{\textbf{h},\textbf{y},1} + b_{\textbf{h},\textbf{y},1})</script><p>则多模态标记分布学习的任务为最小化分类交叉熵损失：</p>
<script type="math/tex; mode=display">
L = -\sum y\cdot log\hat{y}</script><h2 id="时序多模态标记分布学习"><a href="#时序多模态标记分布学习" class="headerlink" title="时序多模态标记分布学习"></a>时序多模态标记分布学习</h2><p>对于时序数据，其特征空间为 <script type="math/tex">\widehat{\mathcal{X}} = \mathbb{R}^{r_s \times T_s} \times \mathbb{R}^{r_1 \times T_1} \times \mathbb{R}^{r_2 \times T_2} \times \cdots \times \mathbb{R}^{r_M \times T_M}</script>，其中<script type="math/tex">T_s</script>表示边信息的时间序列，<script type="math/tex">T_m</script>则表示第 <script type="math/tex">m</script> 个模态的时间序列。本文根据时序数据特点，提出了先融合多模态标记分布学习和后融合标记分布学习算法。</p>
<p>对于各个模态数据可对齐，且边信息会随时发生改变的时序数据，即<script type="math/tex">T_s = T_1 = T_2 = \cdots = T_m</script>，如图1所示的视频数据，本文提出先融合多模态标记分布。首先将边信息与各个模态在时间轴上进行对齐，并根据多模态标记分布学习框架进行融合，然后采用双向LSTM对融合后的时序特征进行学习：</p>
<script type="math/tex; mode=display">
\textbf{H} = BiLSTM(\textbf{X}_F)</script><p>其中，<script type="math/tex">\textbf{X}_F = [ \textbf{x}_F^1, \textbf{x}_F^2, \cdots, \textbf{x}_F^T]</script>为融合后的时序特征，利用注意力机制进行池化：</p>
<script type="math/tex; mode=display">
\textbf{H}_a = \textbf{a} \textbf{H}  \\
\textbf{a} = softmax( \textbf{H}\textbf{w}_a )</script><p>则融合后特征到任务标记的映射变为：</p>
<script type="math/tex; mode=display">
\hat{\textbf{y}} = sigmoid( \textbf{h}_H \textbf{w}_{\hat{y}} +b_{\hat{y}}) \\
\textbf{h}_H = \sigma( \textbf{h}_{H,1} \textbf{w}_{H} + b_{H}) \\
\textbf{h}_{H,1} = \sigma( \textbf{H}_a \textbf{w}_{H,1} + b_{H,1})</script><p>而对于各个模态无法对齐，且边信息不会发生改变的时序数据，如多模态疾病预测问题中，我们可以将患者信息作为边信息，而其检查结果作为多模态特征，则在该次就诊时患者信息不会发生改变，且检查结果数据之间不存在对齐，本文提出了后融合多模态标记分布学习。首先采用双向LSTM对时序数据进行特征表达：</p>
<script type="math/tex; mode=display">
\textbf{H}_m = BiLSTM(\textbf{X}_m), 1 \le m \le M</script><p>其中， <script type="math/tex">\textbf{X}_m = [\textbf{x}_m^1, \textbf{x}_m^2, \cdots, \textbf{x}_m^{T_m}]</script>为第<script type="math/tex">m</script>个模态的时序数据，同样采用注意力机制进行池化：</p>
<script type="math/tex; mode=display">
\textbf{h}_{m,a} = \textbf{a}_m \textbf{H}_m\\
\textbf{a}_{m} = softmax( \textbf{H}_m \textbf{w}_{a,m} )</script><p>则<script type="math/tex">\textbf{h}_{m,a}</script>可以替代多模态标记分布学习框架中的 <script type="math/tex">\textbf{x}_m</script>进行多模态融合。</p>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>本文将先融合多模态标记分布学习算法应用于情感分析任务，并在CMU-MOSI与CMU-MOSEI数据集上进行实验，与现有先进算法进行比较，展现出了更好的鲁棒性。如图3所示，为部分实验结果，展示了随着环境变化，各个模态重要性发生改变。</p>
<p><img src="/img/results.png" alt="图3. 部分实验结果展示。"></p>
<p>本文将后融合多模态标记分布学习算法应用于疾病诊断任务，在MIMIC-III数据集上进行实验。采用Word2vec方法将结构化的患者特征与检查结果进行词嵌入，从而挖掘特征间的潜在联系。该算法与现有先进算法进行比较，表现出更高的准确性与泛化能力。</p>
</div><div class="tags"><a href="/tags/Machine Learning"><i class="fa fa-tag">Machine Learning</i></a></div><div class="post-nav"><a class="pre" href="/2022/10/11/tensorflow-1/">Tensorflow模型</a><a class="next" href="/2021/08/12/cat/">大黄饲养笔记</a></div><div id="vcomment"></div><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="//unpkg.com/valine@latest/dist/Valine.min.js"></script><script>var notify = 'false' == 'true' ? true : false;
var verify = 'false' == 'true' ? true : false;
var GUEST_INFO = ['nick','mail','link'];
var guest_info = 'nick,mail,link'.split(',').filter(function(item){
  return GUEST_INFO.indexOf(item) > -1
});
guest_info = guest_info.length == 0 ? GUEST_INFO :guest_info;
window.valine = new Valine({
  el:'#vcomment',
  notify:notify,
  verify:verify,
  appId:'AMlVKrsPTMdYDOomfWIdGiFC-gzGzoHsz',
  appKey:'Msy2N1GDdBCf0W3MY9fjRYHc',
  placeholder:'Comments',
  avatar:'mm',
  guest_info:guest_info,
  pageSize:'10'
})
</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"><input type="hidden" name="sitesearch" value="https://github.com/sceliay"></form></div><div class="widget"><div class="author-info"><a class="info-avatar" href="/about/" title="关于"><img src="/img/head.jpg"></a><p>YRen</p><a class="info-icon" href="https://github.com/sceliay" title="Github" target="_blank" style="margin-inline:5px"> <i class="fa fa-github-square" style="margin-inline:5px"></i></a><a class="info-icon" href="mailto:yren@zhejianglab.com" title="Email" target="_blank" style="margin-inline:5px"> <i class="fa fa-envelope-square" style="margin-inline:5px"></i></a><a class="info-icon" href="https://twitter.com/yren_zj" title="Twitter" target="_blank" style="margin-inline:5px"> <i class="fa fa-twitter-square" style="margin-inline:5px"></i></a><a class="info-icon" href="https://weibo.com/u/2265958580" title="weibo" target="_blank" style="margin-inline:5px"> <i class="fa fa-weibo" style="margin-inline:5px"></i></a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/AI-for-Medicine/">AI for Medicine</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Machine-Learning/">Machine Learning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Notes/">Notes</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Pytorch/">Pytorch</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Tensorflow/">Tensorflow</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/Matplotlib/" style="font-size: 15px;">Matplotlib</a> <a href="/tags/Machine-Learning/" style="font-size: 15px;">Machine Learning</a> <a href="/tags/Medicine/" style="font-size: 15px;">Medicine</a> <a href="/tags/Theano/" style="font-size: 15px;">Theano</a> <a href="/tags/Anaconda/" style="font-size: 15px;">Anaconda</a> <a href="/tags/tmux/" style="font-size: 15px;">tmux</a> <a href="/tags/hexo/" style="font-size: 15px;">hexo</a> <a href="/tags/Jupyter/" style="font-size: 15px;">Jupyter</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/BERT/" style="font-size: 15px;">BERT</a> <a href="/tags/Pandas/" style="font-size: 15px;">Pandas</a> <a href="/tags/Data-Structure/" style="font-size: 15px;">Data Structure</a> <a href="/tags/sklearn/" style="font-size: 15px;">sklearn</a> <a href="/tags/quality/" style="font-size: 15px;">quality</a> <a href="/tags/Pytorch/" style="font-size: 15px;">Pytorch</a> <a href="/tags/Tensorflow/" style="font-size: 15px;">Tensorflow</a> <a href="/tags/Daily/" style="font-size: 15px;">Daily</a> <a href="/tags/Keras/" style="font-size: 15px;">Keras</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2023/04/06/emergency-ML/">ML for Emergency</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/03/22/acute/">急危重症预测</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/03/09/heterogeneousHealthcare/">Advances in Mining Heterogeneous Healthcare Data</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/02/28/association/">Association mining</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/02/17/transRL/">迁移强化学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/02/16/mimic/">MIMIC 数据集</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/02/03/emergency/">医疗保障急救技术</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/01/12/sepsis/">脓毒症</a></li><li class="post-list-item"><a class="post-list-link" href="/2023/01/09/treatment-medicines-prediction/">Prediction of Treatment Medicines</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/12/15/label-enhancement/">Label Enhancement</a></li></ul></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2023 <a href="/." rel="nofollow">YRen's Blog.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/latest/jquery.fancybox.min.js"></script><script type="text/javascript" src="/js/fancybox.js?v=1.0.0"></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/latest/jquery.fancybox.min.css"><script type="text/javascript" src="/js/copycode.js?v=1.0.0" successtext="复制成功!"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css?v=1.0.0"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=1.0.0"></script></div></body></html>