<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>Keras 学习笔记(2) | Sceliay's Blog</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/latest/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/latest/pure-min.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/latest/grids-responsive-min.min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/latest/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script type="text/javascript" src="//lib.baomitu.com/clipboard.js/latest/clipboard.min.js"></script><script type="text/javascript" src="//lib.baomitu.com/toastr.js/latest/toastr.min.js"></script><link rel="stylesheet" href="//lib.baomitu.com/toastr.js/latest/toastr.min.css"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Keras 学习笔记(2)</h1><a id="logo" href="/.">Sceliay's Blog</a><p class="description">Welcome to my blog!</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 主页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/tags/"><i class="fa fa-tags"> 标签</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Keras 学习笔记(2)</h1><div class="post-meta">2021-03-13<span> | </span><span class="category"><a href="/categories/Machine-Learning/">Machine Learning</a></span></div><div class="post-content"><ol>
<li><a href="https://keras.io/zh/layers/recurrent/" target="_blank" rel="noopener">RNN (LSTM, GRU) 模型</a></li>
</ol>
<ul>
<li><code>lstm1, lstm_h, lstm_c = LSTM(hideen_size, return_sequences=True, return_state=True)(input)</code><br>返回lstm的每层隐状态<code>lstm1</code>,最后输出<code>lstm_h</code>,最后的单元状态<code>lstm_c</code>。</li>
</ul>
<ol>
<li><a href="https://keras.io/api/layers/recurrent_layers/bidirectional/" target="_blank" rel="noopener">Bidirenctial layer</a></li>
</ol>
<ul>
<li><code>lstm_out = Bidirectional(LSTM(10, return_sequences=True)(input))</code></li>
<li><p>也可以分开写</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">forward_layer = LSTM(10, return_sequences=True)(input)</span><br><span class="line">backward_layer = LSTM(10, activation=&apos;relu&apos;, return_sequences=True,</span><br><span class="line">                       go_backwards=True)(input)</span><br></pre></td></tr></table></figure>
</li>
<li><p><a href="https://stackoverflow.com/questions/47923370/keras-bidirectional-lstm-seq2seq" target="_blank" rel="noopener">使用<code>return_state</code></a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">encoder_inputs = Input(shape=(None, num_encoder_tokens))</span><br><span class="line">encoder = Bidirectional(LSTM(latent_dim, return_state=True))</span><br><span class="line">encoder_outputs, forward_h, forward_c, backward_h, backward_c = encoder(encoder_inputs)</span><br><span class="line"></span><br><span class="line">state_h = Concatenate()([forward_h, backward_h])</span><br><span class="line">state_c = Concatenate()([forward_c, backward_c])</span><br><span class="line"></span><br><span class="line">encoder_states = [state_h, state_c]</span><br><span class="line"></span><br><span class="line">decoder_inputs = Input(shape=(None, num_decoder_tokens))</span><br><span class="line">decoder_lstm = LSTM(latent_dim * 2, return_sequences=True, return_state=True)</span><br><span class="line">decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<ol>
<li><a href="https://www.sohu.com/a/407812302_500659" target="_blank" rel="noopener">mask 使用方法</a></li>
</ol>
<ul>
<li><p>Masking layer:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mask = keras.layers.Masking(mask_value= 0, input_shape=(time_step,feature_size))(input)</span><br><span class="line">lstm_output = keras.layers.LSTM(hidden_size, return_sequences= True)(mask)</span><br></pre></td></tr></table></figure>
</li>
<li><p>Embedding layer:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">embed = keras.layers.Embedding(vocab_size, embedding_size, mask_zero= True)(input)</span><br><span class="line">lstm_output = keras.layers.LSTM(hidden_size, return_sequences= True)(emded)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<ol>
<li><a href="https://keras.io/zh/optimizers/" target="_blank" rel="noopener">optimizer</a></li>
</ol>
<ul>
<li><code>tf.keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)</code><ul>
<li><code>decay</code>: 学习率衰减</li>
</ul>
</li>
<li><p>Learning rate</p>
<ul>
<li><p>tf 2.0 <code>tf.keras.optimizers.schedules.LearningRateSchedule</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):</span><br><span class="line">    def __init__(self, d_model, warmup_steps=4000):</span><br><span class="line">        super(CustomSchedule, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.d_model = d_model</span><br><span class="line">        self.d_model = tf.cast(self.d_model, tf.float32)</span><br><span class="line"></span><br><span class="line">        self.warmup_steps = warmup_steps</span><br><span class="line"></span><br><span class="line">    def __call__(self, step):</span><br><span class="line">        arg1 = tf.math.rsqrt(step)</span><br><span class="line">        arg2 = step * (self.warmup_steps ** -1.5)</span><br><span class="line"></span><br><span class="line">        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)</span><br><span class="line"></span><br><span class="line">learning_rate = CustomSchedule(200)</span><br><span class="line">custom_adam = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, </span><br><span class="line">                                 epsilon=1e-9)</span><br></pre></td></tr></table></figure>
</li>
<li><p>keras: <code>keras.callbacks.LearningRateScheduler(schedule)</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">import keras.backend as K</span><br><span class="line">from keras.callbacks import LearningRateScheduler</span><br><span class="line"> </span><br><span class="line">def scheduler(epoch):</span><br><span class="line">    # 每隔100个epoch，学习率减小为原来的1/10</span><br><span class="line">    if epoch % 100 == 0 and epoch != 0:</span><br><span class="line">        lr = K.get_value(model.optimizer.lr)</span><br><span class="line">        K.set_value(model.optimizer.lr, lr * 0.1)</span><br><span class="line">        print(&quot;lr changed to &#123;&#125;&quot;.format(lr * 0.1))</span><br><span class="line">    return K.get_value(model.optimizer.lr)</span><br><span class="line"> </span><br><span class="line">reduce_lr = LearningRateScheduler(scheduler)</span><br><span class="line">model.fit(train_x, train_y, batch_size=32, epochs=300, callbacks=[reduce_lr])</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p><a href="https://blog.csdn.net/zzc15806/article/details/79711114" target="_blank" rel="noopener">Reduce LR On Plateau</a><br><code>keras.callbacks.ReduceLROnPlateau(monitor=&#39;val_loss&#39;, factor=0.1, patience=10, verbose=0, mode=&#39;auto&#39;, epsilon=0.0001, cooldown=0, min_lr=0)</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">from keras.callbacks import ReduceLROnPlateau</span><br><span class="line">reduce_lr = ReduceLROnPlateau(monitor=&apos;val_loss&apos;, patience=10, mode=&apos;auto&apos;)</span><br><span class="line">model.fit(train_x, train_y, batch_size=32, epochs=300, validation_split=0.1, callbacks=[reduce_lr])</span><br></pre></td></tr></table></figure></li>
</ul>
</div><div class="tags"><a href="/tags/Python"><i class="fa fa-tag">Python</i></a><a href="/tags/Machine Learning"><i class="fa fa-tag">Machine Learning</i></a><a href="/tags/Keras"><i class="fa fa-tag">Keras</i></a><a href="/tags/Tensorflow"><i class="fa fa-tag">Tensorflow</i></a></div><div class="post-nav"><a class="pre" href="/2022/04/18/mldl/">MLDL</a><a class="next" href="/2020/05/20/BERT/">BERT</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"><input type="hidden" name="sitesearch" value="https://github.com/sceliay"></form></div><div class="widget"><div class="author-info"><a class="info-avatar" href="/about/" title="关于"><img src="/img/head.jpg"></a><p>当你凝视深渊的时候，深渊也在凝视着你。</p><a class="info-icon" href="https://twitter.com/yren_zj" title="Twitter" target="_blank" style="margin-inline:5px"> <i class="fa fa-twitter-square" style="margin-inline:5px"></i></a><a class="info-icon" href="yren@zhejianglab.com" title="Email" target="_blank" style="margin-inline:5px"> <i class="fa fa-envelope-square" style="margin-inline:5px"></i></a><a class="info-icon" href="https://github.com/sceliay" title="Github" target="_blank" style="margin-inline:5px"> <i class="fa fa-github-square" style="margin-inline:5px"></i></a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Data-Structure/">Data Structure</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Machine-Learning/">Machine Learning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Notes/">Notes</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/Jupyter/" style="font-size: 15px;">Jupyter</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/Embedding/" style="font-size: 15px;">Embedding</a> <a href="/tags/Theano/" style="font-size: 15px;">Theano</a> <a href="/tags/Anaconda/" style="font-size: 15px;">Anaconda</a> <a href="/tags/tmux/" style="font-size: 15px;">tmux</a> <a href="/tags/hexo/" style="font-size: 15px;">hexo</a> <a href="/tags/Machine-Learning/" style="font-size: 15px;">Machine Learning</a> <a href="/tags/Keras/" style="font-size: 15px;">Keras</a> <a href="/tags/Tensorflow/" style="font-size: 15px;">Tensorflow</a> <a href="/tags/EHR/" style="font-size: 15px;">EHR</a> <a href="/tags/Data-Structure/" style="font-size: 15px;">Data Structure</a> <a href="/tags/Pandas/" style="font-size: 15px;">Pandas</a> <a href="/tags/Pytorch/" style="font-size: 15px;">Pytorch</a> <a href="/tags/quality/" style="font-size: 15px;">quality</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2022/09/26/med-bert/">Med BERT</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/04/18/mldl/">MLDL</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/03/13/keras-1/">Keras 学习笔记(2)</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/05/20/BERT/">BERT</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/28/ai4md2/">AI for Medicine(2)</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/26/offer/">剑指offer</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/23/matplotlib/">Matplotlib</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/22/ai4md/">AI for Medicine</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/01/ml/">Machine Learning</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/30/tensorflow-2-0/">tensorflow-2.x</a></li></ul></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2022 <a href="/." rel="nofollow">Sceliay's Blog.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/latest/jquery.fancybox.min.js"></script><script type="text/javascript" src="/js/fancybox.js?v=1.0.0"></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/latest/jquery.fancybox.min.css"><script type="text/javascript" src="/js/copycode.js?v=1.0.0" successtext="复制成功!"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css?v=1.0.0"><script type="text/javascript" src="/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=1.0.0"></script></div></body></html>